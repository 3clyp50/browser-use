---
title: "Getting Started Examples"
description: "Practical examples to help you get started with browser-use"
icon: "code"
---

This page showcases 5 practical examples to help you understand what browser-use can do. Each example demonstrates different capabilities and use cases.

<Note>
  For the complete collection of examples and more advanced use cases, visit our [examples folder on GitHub](https://github.com/browser-use/browser-use/tree/main/examples).
</Note>

## 1. Basic Web Search

The simplest way to get started - perform a Google search and get results.

```python
import asyncio
import os
import sys
from dotenv import load_dotenv

load_dotenv()

from browser_use import Agent, ChatOpenAI

async def main():
    llm = ChatOpenAI(model='gpt-4.1-mini')
    task = "Search Google for 'what is browser automation' and tell me the top 3 results"
    agent = Agent(task=task, llm=llm)
    await agent.run()

if __name__ == '__main__':
    asyncio.run(main())
```

**What this does:** Opens a browser, navigates to Google, performs a search, and extracts the top search results.

## 2. Form Filling and Submission

Learn how to interact with web forms - filling fields and submitting data.

```python
import asyncio
from dotenv import load_dotenv

load_dotenv()

from browser_use import Agent, ChatOpenAI

async def main():
    llm = ChatOpenAI(model='gpt-4.1-mini')
    
    task = """
    Go to https://httpbin.org/forms/post and fill out the contact form with:
    - Customer name: John Doe
    - Telephone: 555-123-4567
    - Email: john.doe@example.com
    - Size: Medium
    - Topping: cheese
    - Delivery time: now
    - Comments: This is a test form submission
    
    Then submit the form and tell me what response you get.
    """
    
    agent = Agent(task=task, llm=llm)
    await agent.run()

if __name__ == '__main__':
    asyncio.run(main())
```

**What this does:** Navigates to a test form, fills out all the required fields with specified data, submits the form, and reports the response.

## 3. Data Extraction from Websites

Extract structured information from web pages efficiently.

```python
import asyncio
from dotenv import load_dotenv

load_dotenv()

from browser_use import Agent, ChatOpenAI

async def main():
    llm = ChatOpenAI(model='gpt-4.1-mini')
    
    task = """
    Go to https://quotes.toscrape.com/ and extract the following information:
    - The first 5 quotes on the page
    - The author of each quote
    - The tags associated with each quote
    
    Present the information in a clear, structured format like:
    Quote 1: "[quote text]" - Author: [author name] - Tags: [tag1, tag2, ...]
    Quote 2: "[quote text]" - Author: [author name] - Tags: [tag1, tag2, ...]
    etc.
    """
    
    agent = Agent(task=task, llm=llm)
    await agent.run()

if __name__ == '__main__':
    asyncio.run(main())
```

**What this does:** Visits a quotes website, systematically extracts quote text, authors, and tags, then presents the data in a structured format.

## 4. Multi-Step Research Task

Perform complex workflows that combine search, navigation, and data collection.

```python
import asyncio
from dotenv import load_dotenv

load_dotenv()

from browser_use import Agent, ChatOpenAI

async def main():
    llm = ChatOpenAI(model='gpt-4.1-mini')
    
    task = """
    I want you to research Python web scraping libraries. Here's what I need:
    
    1. First, search Google for "best Python web scraping libraries 2024"
    2. Find a reputable article or blog post about this topic
    3. From that article, extract the top 3 recommended libraries
    4. For each library, visit its official website or GitHub page
    5. Extract key information about each library:
       - Name
       - Brief description
       - Main features or advantages
       - GitHub stars (if available)
    
    Present your findings in a summary format comparing the three libraries.
    """
    
    agent = Agent(task=task, llm=llm)
    await agent.run()

if __name__ == '__main__':
    asyncio.run(main())
```

**What this does:** Performs multi-step research by searching, finding articles, extracting recommendations, visiting multiple sites, and compiling a comprehensive comparison report.

## 5. High-Speed Agent with Parallel Processing

Optimize for speed and handle multiple tasks simultaneously.

```python
import asyncio
from dotenv import load_dotenv

load_dotenv()

from browser_use import Agent, BrowserProfile

# Speed optimization instructions for the model
SPEED_OPTIMIZATION_PROMPT = """
SPEED OPTIMIZATION INSTRUCTIONS:
- Be extremely concise and direct in your responses
- Get to the goal as quickly as possible
- Use multi-action sequences whenever possible to reduce steps
"""

async def main():
    # Use fast LLM - Llama on Groq for ultra-fast inference
    from browser_use import ChatGroq
    
    llm = ChatGroq(
        model='meta-llama/llama-4-maverick-17b-128e-instruct',
        temperature=0.0,
    )
    
    # Create speed-optimized browser profile
    browser_profile = BrowserProfile(
        minimum_wait_page_load_time=0.1,
        wait_between_actions=0.1,
        headless=False,
    )
    
    task = """
    1. Go to reddit https://www.reddit.com/search/?q=browser+agent&type=communities 
    2. Click directly on the first 5 communities to open each in new tabs
    3. Find out what the latest post is about, and switch directly to the next tab
    4. Return the latest post summary for each page
    """
    
    # Create agent with all speed optimizations
    agent = Agent(
        task=task,
        llm=llm,
        flash_mode=True,  # Disables thinking in the LLM output for maximum speed
        browser_profile=browser_profile,
        extend_system_message=SPEED_OPTIMIZATION_PROMPT,
    )
    
    await agent.run()

if __name__ == '__main__':
    asyncio.run(main())
```

**What this does:** Demonstrates speed optimization techniques including fast LLM models, optimized browser settings, flash mode, and parallel tab processing for maximum performance.

## Next Steps

These examples cover the core capabilities of browser-use:

- **Basic automation** - Simple search and navigation
- **Form interactions** - Filling and submitting data
- **Data extraction** - Getting structured information from websites
- **Complex workflows** - Multi-step research and analysis
- **Performance optimization** - Speed and parallel processing

<Card title="Explore More Examples" icon="github" href="https://github.com/browser-use/browser-use/tree/main/examples">
  Browse our complete examples collection on GitHub for more advanced use cases including:
  - Custom functions and action filters
  - E-commerce and shopping automation
  - API integrations and file handling
  - Security features and authentication
  - Cloud deployment patterns
</Card>

## Prerequisites

Before running these examples, make sure you have:

1. **Installed browser-use**: `uv pip install browser-use`
2. **Installed Chromium**: `uvx playwright install chromium --with-deps`
3. **Set up your LLM API key** in a `.env` file (see [Supported Models](/customize/supported-models))
4. **Python 3.11+** with asyncio support

Each example is self-contained and can be run independently. Start with the basic search example and progressively work through more complex scenarios.